{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "import os\n",
    "import h5py\n",
    "import os.path as op\n",
    "import matplotlib\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.widgets import Slider, Button, RadioButtons\n",
    "import matplotlib.pyplot as plt\n",
    "import array\n",
    "%matplotlib inline\n",
    "sys.path.append('..')\n",
    "from zwatershed import *\n",
    "from edgelist_methods import *\n",
    "path_to_folder = '/Users/chandansingh/drive/janelia/conv_net_scripts/'\n",
    "path_to_data = path_to_folder + 'data/'\n",
    "from multiprocessing import Pool\n",
    "import nyroglancer\n",
    "\n",
    "# -------------------------------- parameters ---------------------------------------\n",
    "gt_seg = '/groups/turaga/home/turagas/data/FlyEM/fibsem_medulla_7col/tstvol-520-1-h5/groundtruth_seg_thick.h5'\n",
    "gt_aff = '/groups/turaga/home/turagas/data/FlyEM/fibsem_medulla_7col/tstvol-520-1-h5/groundtruth_aff.h5'\n",
    "# pred_file = '/groups/turaga/home/turagas/research/caffe_v2/processed/bock2/120000/sample_A_x1_y1_z1_xy1.h5'\n",
    "# pred_file_2 = '/groups/turaga/home/turagas/research/caffe_v2/processed/bock2/120000/cutout_3k.h5'\n",
    "pred_file = '/groups/turaga/home/turagas/turagalab/FROM_TIER2/singhc/train/output_200000/tstvol-1_2.h5'\n",
    "\n",
    "out_folder = '/nobackup/turaga/singhc/par_zwshed_3/'\n",
    "outname = out_folder+'out.h5'\n",
    "threshes = [2000]\n",
    "cmap = matplotlib.colors.ListedColormap(np.vstack(((0, 0, 0), np.random.rand(255, 3))))\n",
    "NUM_WORKERS = 16\n",
    "MAX_LEN = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divide Volumes, set up args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dims [432 432 432]\n",
      "num_vols [3 3 3]\n",
      "deltas [144 144 144]\n"
     ]
    }
   ],
   "source": [
    "from par_funcs import partition_subvols\n",
    "args,starts,ends = partition_subvols(pred_file,out_folder,max_len=MAX_LEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call Watershed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished /nobackup/turaga/singhc/par_zwshed_3/141_285_0_vol0/ watershed\n",
      "finished /nobackup/turaga/singhc/par_zwshed_3/0_285_0_vol0/ watershed\n",
      "finished /nobackup/turaga/singhc/par_zwshed_3/0_0_0_vol0/ watershed\n",
      "finished /nobackup/turaga/singhc/par_zwshed_3/0_141_0_vol0/ watershed\n",
      "finished /nobackup/turaga/singhc/par_zwshed_3/0_285_285_vol0/ watershed\n",
      "finished /nobackup/turaga/singhc/par_zwshed_3/0_285_141_vol0/ watershed\n",
      "finished /nobackup/turaga/singhc/par_zwshed_3/141_0_0_vol0/ watershed\n",
      "finished /nobackup/turaga/singhc/par_zwshed_3/0_0_285_vol0/ watershed\n",
      "finished /nobackup/turaga/singhc/par_zwshed_3/0_0_141_vol0/ watershed\n",
      "finished /nobackup/turaga/singhc/par_zwshed_3/141_141_141_vol0/ watershed\n",
      "finished /nobackup/turaga/singhc/par_zwshed_3/141_141_285_vol0/ watershed\n",
      "finished /nobackup/turaga/singhc/par_zwshed_3/141_0_285_vol0/ watershed\n",
      "finished /nobackup/turaga/singhc/par_zwshed_3/0_141_285_vol0/ watershed\n",
      "finished /nobackup/turaga/singhc/par_zwshed_3/141_141_0_vol0/ watershed\n",
      "finished /nobackup/turaga/singhc/par_zwshed_3/0_141_141_vol0/ watershed\n",
      "finished /nobackup/turaga/singhc/par_zwshed_3/141_0_141_vol0/ watershed\n",
      "finishedfinishedfinishedfinishedfinishedfinishedfinishedfinishedfinishedfinishedfinished /nobackup/turaga/singhc/par_zwshed_3/141_285_141_vol0/ watershed\n",
      " /nobackup/turaga/singhc/par_zwshed_3/141_285_285_vol0/ watershed\n",
      " /nobackup/turaga/singhc/par_zwshed_3/285_0_0_vol0/ watershed\n",
      " /nobackup/turaga/singhc/par_zwshed_3/285_0_141_vol0/ watershed\n",
      " /nobackup/turaga/singhc/par_zwshed_3/285_0_285_vol0/ watershed\n",
      " /nobackup/turaga/singhc/par_zwshed_3/285_141_0_vol0/ watershed\n",
      " /nobackup/turaga/singhc/par_zwshed_3/285_141_141_vol0/ watershed\n",
      " /nobackup/turaga/singhc/par_zwshed_3/285_141_285_vol0/ watershed\n",
      " /nobackup/turaga/singhc/par_zwshed_3/285_285_0_vol0/ watershed\n",
      " /nobackup/turaga/singhc/par_zwshed_3/285_285_141_vol0/ watershed\n",
      " /nobackup/turaga/singhc/par_zwshed_3/285_285_285_vol0/ watershed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def zwshed_h5_par(arg):\n",
    "    (pred_file,s,e,seg_save_path) = arg\n",
    "    f = h5py.File(pred_file, 'r')\n",
    "    preds_small = f['main']\n",
    "    pred_vol = preds_small[:,s[0]:e[0],s[1]:e[1],s[2]:e[2]]\n",
    "    zwatershed_basic_h5(pred_vol,seg_save_path)\n",
    "    print \"finished\",seg_save_path,\"watershed\"\n",
    "p = Pool(NUM_WORKERS)\n",
    "p.map(zwshed_h5_par, args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if op.isfile(outname):\n",
    "    os.remove(outname)\n",
    "f = h5py.File(outname, 'a')\n",
    "\n",
    "dset_seg = f.create_dataset('seg', dims, dtype='uint64', chunks=True)\n",
    "filename = 'basic.h5'\n",
    "inc,re,merges,rgs=0,{},{},{}\n",
    "X,Y,Z = (1,1,2)\n",
    "# calc merges, set dset_seg, rg with incrementing\n",
    "for x in range(X): #num_vols[0]):\n",
    "    for y in range(Y): #num_vols[1]):        \n",
    "        for z in range(Z): #num_vols[2]): \n",
    "            i = x*num_vols[1]*num_vols[2]+y*num_vols[2]+z\n",
    "            arg,s,e = args[i],starts[i],ends[i]\n",
    "            basic_file = h5py.File(arg[1]+filename,'r')\n",
    "            seg,rg = np.array(basic_file['seg']),np.array(basic_file['rg'])\n",
    "            seg[seg!=0]+=inc\n",
    "            rg[:,:2] += inc\n",
    "            rgs[i] = rg\n",
    "            inc = np.max(seg)\n",
    "            print \"i,x,y,z\",i,x,y,z\n",
    "            if not z==0: \n",
    "                re,merges = calc_merges(edge_mins=dset_seg[s[0]:e[0],s[1]:e[1],s[2]+3],edge_maxes=seg[:,:,3], re=re, merges=merges)\n",
    "            if not y==0:\n",
    "                re,merges = calc_merges(edge_mins=dset_seg[s[0]:e[0],s[1]+3,s[2]:e[2]],edge_maxes=seg[:,3,:],re=re,merges=merges)\n",
    "            if not x==0:\n",
    "                re,merges = calc_merges(edge_mins=dset_seg[s[0]+3,s[1]:e[1],s[2]:e[2]],edge_maxes=seg[3,:,:],re=re, merges=merges)\n",
    "            dset_seg[s[0]:e[0],s[1]:e[1],s[2]:e[2]] = seg[:,:,:]\n",
    "\n",
    "merges_filtered = filter_merges(merges)            \n",
    "rgs = merge(merges_filtered,rgs,(X,Y,Z),(args,starts,ends),f,max_val=inc,p=True)\n",
    "renum,seg_sizes,rgs = renum_all(f['seg'],rgs,(X,Y,Z),(args,starts,ends),f,p=True)\n",
    "\n",
    "\n",
    "# save\n",
    "dset_seg_sizes = f.create_dataset('seg_sizes', data=np.array(seg_sizes))\n",
    "for key in rgs:\n",
    "    rg_dset = f.create_dataset('rg_'+str(key),data=np.array(rgs[key]))\n",
    "dset_starts = f.create_dataset('starts',data=np.array(starts))\n",
    "dset_ends = f.create_dataset('ends',data=np.array(ends))                               \n",
    "f.close()   \n",
    "# display_seg_xy(dset_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# stitch methods\n",
    "def calc_merges(edge_mins,edge_maxes, re, merges={}):\n",
    "    edge_mins = edge_mins.ravel()\n",
    "    edge_maxes = edge_maxes.ravel()\n",
    "    for j in range(len(edge_mins)):\n",
    "        edge_min = edge_mins[j]\n",
    "        edge_max = edge_maxes[j]\n",
    "        if not edge_min==0 and not edge_max==0:\n",
    "            if not edge_max==edge_min:\n",
    "                if edge_max in re: # already in map\n",
    "                    old_min = re[edge_max]\n",
    "                    merge_max = max(old_min,edge_min)\n",
    "                    merge_min = min(old_min,edge_min)\n",
    "                    if not merge_max==merge_min:\n",
    "                        re[merge_max] = merge_min\n",
    "                        add_or_inc(merge_max,merge_min,merges)\n",
    "            re[edge_max] = edge_min\n",
    "            add_or_inc(edge_max,edge_min,merges)\n",
    "    return re, merges  \n",
    "\n",
    "def add_or_inc(key_max,key_min,d):\n",
    "    key = (key_max,key_min)\n",
    "    if not key in d:\n",
    "        d[key] = 1\n",
    "    else:\n",
    "        d[key] +=1\n",
    "\n",
    "def filter_merges(merges):\n",
    "    COUNT_THRESH = 0\n",
    "    print \"\\tfilter merges...\"\n",
    "    # only keep strongest edges\n",
    "    renums = {}\n",
    "    count_maxes = {}\n",
    "    for pair in merges:\n",
    "        count = merges[pair]\n",
    "        e1,e2 = pair\n",
    "        if e1 in count_maxes:\n",
    "            if count > count_maxes[e1]:\n",
    "                renums[e1] = e2\n",
    "                count_maxes[e1] = count\n",
    "        else:\n",
    "            renums[e1] = e2\n",
    "            count_maxes[e1] = count\n",
    "    \n",
    "    # compress merges\n",
    "    sum_counts = 0\n",
    "    for key in merges:\n",
    "        sum_counts += merges[key]\n",
    "    renums_filtered = {}\n",
    "    print \"\\tmerging numbers,\",len(renums.keys()),\"keys ... \"            \n",
    "    for key in renums:\n",
    "        val = renums[key]\n",
    "        if merges[(key,val)] > COUNT_THRESH:\n",
    "            while val in renums:\n",
    "                val = renums[val]\n",
    "            renums_filtered[key] = val\n",
    "    return renums_filtered\n",
    "\n",
    "def merge(merges_filtered,rgs,(X,Y,Z),(args,starts,ends),f,max_val=1e5,p=False):     \n",
    "    # merge segs\n",
    "#     print \"\\tbefore nsegs=\",len(np.unique(dset_seg)),\"num0=\",np.sum(dset_seg==0)\n",
    "    if p:\n",
    "        fig = plt.figure(figsize=(15, 7))\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.imshow(dset_seg[0, :, :], cmap=cmap)\n",
    "        \n",
    "    mp = np.arange(0,max_val+1,dtype='uint64')\n",
    "    mp[merges_filtered.keys()] = merges_filtered.values()\n",
    "    for x in range(X): #num_vols[0]):\n",
    "        for y in range(Y): #num_vols[1]):        \n",
    "            for z in range(Z): #num_vols[2]): \n",
    "                i = x*num_vols[1]*num_vols[2]+y*num_vols[2]+z\n",
    "                arg,s,e = args[i],starts[i],ends[i]\n",
    "                seg = np.array(dset_seg[s[0]:e[0],s[1]:e[1],s[2]:e[2]])\n",
    "                f['seg'][s[0]:e[0],s[1]:e[1],s[2]:e[2]] = mp[seg]\n",
    "    if p:\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.imshow(f['seg'][0, :, :], cmap=cmap)\n",
    "    plt.show()\n",
    "    \n",
    "    # merge rgs\n",
    "    for key in rgs:\n",
    "        rg = rgs[key]\n",
    "        rg_to_renum = rg[:,:2].astype('int')\n",
    "        rg[:,:2] = mp[rg_to_renum]\n",
    "        keeps = rg[:,0]!=rg[:,1]\n",
    "        rg_filtered = rg[keeps,:]\n",
    "        rgs[key] = rg_filtered\n",
    "    \n",
    "                \n",
    "    return rgs\n",
    "\n",
    "def renum_all(seg,rgs,(X,Y,Z),(args,starts,ends),f,p=False): # there must be at least one background pixel   \n",
    "    segId,seg_sizes = np.unique(seg,return_counts=True) # this might have to be done in parts\n",
    "    renum = np.zeros(segId.max()+1,dtype=np.uint64)\n",
    "    renum[segId] = np.arange(0,len(segId)+1) \n",
    "\n",
    "    for x in range(X): #num_vols[0]):\n",
    "        for y in range(Y): #num_vols[1]):        \n",
    "            for z in range(Z): #num_vols[2]): \n",
    "                i = x*num_vols[1]*num_vols[2]+y*num_vols[2]+z\n",
    "                arg,s,e = args[i],starts[i],ends[i]\n",
    "                seg = np.array(dset_seg[s[0]:e[0],s[1]:e[1],s[2]:e[2]])\n",
    "                f['seg'][s[0]:e[0],s[1]:e[1],s[2]:e[2]] = renum[seg]\n",
    "    if p:\n",
    "        plt.imshow(dset_seg[0, :, :], cmap=cmap)\n",
    "    plt.show()\n",
    "    \n",
    "    # renumber rgs\n",
    "    for key in rgs:\n",
    "        rg = rgs[key]\n",
    "        rg_to_renum = rg[:,:2].astype('int64')\n",
    "#         rg[:,:2] = renum[rg_to_renum]\n",
    "        rgs[key] = rg\n",
    "\n",
    "    return renum, seg_sizes, rgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agglomeration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def merge_by_thresh(seg,seg_sizes,rg,thresh):\n",
    "    re = {}\n",
    "    seg_max = np.max(seg)\n",
    "    print \"calculating renums...\"\n",
    "    for i in range(rg.shape[0]):\n",
    "        n1,n2,w = rg[i,:]\n",
    "        size = w*w*thresh\n",
    "        if seg_sizes[n1] < size or seg_sizes[n2] < size:\n",
    "            re[n2]=n1\n",
    "            seg_sizes[n1]+=seg_sizes[n2]\n",
    "            seg_sizes[n2]+=seg_sizes[n1]\n",
    "    re_filtered = {}\n",
    "    print \"filtering renums...\"\n",
    "    for key in re:\n",
    "        val = re[key]\n",
    "        while val in re:\n",
    "            val = re[val]\n",
    "        if key < seg_max and val < seg_max:\n",
    "            re_filtered[key] = val\n",
    "    print \"renumbering...\"\n",
    "    mp = np.arange(0,seg_max+1,dtype='uint64')\n",
    "    mp[re_filtered.keys()] = re_filtered.values()\n",
    "    seg = mp[seg]\n",
    "    return seg\n",
    "\n",
    "num,thresh = 0,2000\n",
    "f = h5py.File(outname, 'a')\n",
    "s,e = f['starts'][num],f['ends'][num]\n",
    "seg = f['seg'][s[0]:e[0],s[1]:e[1],s[2]:e[2]]\n",
    "seg_sizes = np.array(f['seg_sizes'])\n",
    "rg = np.array(f['rg_'+str(num)])\n",
    "f.close()\n",
    "\n",
    "seg_merged = merge_by_thresh(seg,seg_sizes,rg,thresh)\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(seg[0,:,:], cmap=cmap)\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(seg_merged[0,:,:], cmap=cmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v = nyroglancer.Viewer()\n",
    "v.set_hostname(\"localhost:8888\")\n",
    "v.put(gt_seg, resolution=[1,1,1], vtype=\"segmentation\", name=\"raw\")\n",
    "v.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
